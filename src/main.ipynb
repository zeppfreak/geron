{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from core.dataset import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "@tf.function\n",
    "def preprocess(line):\n",
    "    n_inputs = 8\n",
    "    \n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x_A = tf.stack(fields[:5])\n",
    "    x_B = tf.stack(fields[2:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x_A, x_B), y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train_filepaths = [\"../data/train.csv\"]\n",
    "valid_filepaths = [\"../data/valid.csv\"]\n",
    "test_filepaths = [\"../data/test.csv\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "train_set = Dataset.csv_reader_dataset(train_filepaths, preprocess, repeat=None)\n",
    "valid_set = Dataset.csv_reader_dataset(valid_filepaths, preprocess)\n",
    "test_set = Dataset.csv_reader_dataset(test_filepaths, preprocess)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x165266670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x165266670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function preprocess at 0x169e6c430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function preprocess at 0x169e6c430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x169e499d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x169e499d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x165d2db80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Dataset.csv_reader_dataset.<locals>.<lambda> at 0x165d2db80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input_A = keras.layers.Input(shape=(5,), name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=(6,), name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "len_train = sum([1 for _ in open('../data/train.csv')])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11611\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "batch_size = 32\n",
    "len_train = sum([1 for _ in open('../data/train.csv')])\n",
    "\n",
    "history = model.fit(train_set, steps_per_epoch=len_train // batch_size, epochs=20, validation_data=valid_set)\n",
    "total_loss, main_loss, aux_loss = model.evaluate(test_set)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x165e97f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x165e97f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-22 21:27:35.510201: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-22 21:27:35.510422: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "340/362 [===========================>..] - ETA: 0s - loss: nan - output_loss: nan - aux_output_loss: nanWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x169b41550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x169b41550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "362/362 [==============================] - 1s 2ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 1ms/step - loss: nan - output_loss: nan - aux_output_loss: nan - val_loss: nan - val_output_loss: nan - val_aux_output_loss: nan\n",
      "162/162 [==============================] - 0s 697us/step - loss: nan - output_loss: nan - aux_output_loss: nan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('python38': conda)"
  },
  "interpreter": {
   "hash": "4d12279a668c09a07e7c4157c546bbb38f9ba185271bedfa9a8304a0c14f888a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}